{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import httpx\n",
    "\n",
    "# Define the endpoint for the containerized API\n",
    "API_URL = \"http://localhost:8000/inference\"  # Update the URL and endpoint as needed\n",
    "\n",
    "# Example data to send in the POST request\n",
    "PAYLOAD = {\"input\": \"This is a test input for the model.\"}\n",
    "\n",
    "# Number of parallel requests\n",
    "NUM_REQUESTS = 10\n",
    "\n",
    "\n",
    "async def send_request(client: httpx.AsyncClient, request_id: int):\n",
    "    \"\"\"Send a single POST request to the containerized API and print the response.\"\"\"\n",
    "    try:\n",
    "        response = await client.post(API_URL, json=PAYLOAD)\n",
    "        print(f\"Request {request_id}: Status {response.status_code}, Response: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request {request_id}: Failed with error: {e}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Send multiple POST requests in parallel.\"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        tasks = [send_request(client, i) for i in range(NUM_REQUESTS)]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the local API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 ms, sys: 10.2 ms, total: 21.1 ms\n",
      "Wall time: 230 ms\n",
      "{'prediction': [{'label': 'POSITIVE', 'score': 0.9997774958610535}]}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:8000/infer'\n",
    "data = {'input': 'I am happy with the new shoes i bought from '}\n",
    "\n",
    "# Send POST request with JSON data\n",
    "%time response = requests.post(url, data=json.dumps(data), headers={'Content-Type': 'application/json'})\n",
    "\n",
    "\n",
    "# Print the response\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"prediction\":[{\"label\":\"POSITIVE\",\"score\":0.9997774958610535}]}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997774958610535}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.text)['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the local docker api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model Inference API'}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://0.0.0.0:8000/'\n",
    "data = {'input': 'This is a positive input for the model.'}\n",
    "# Send POST request with JSON data\n",
    "#%time response = requests.post(url, data=json.dumps(data), headers={'Content-Type': 'application/json'})\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS docker api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"I love this product!\"}}]}\n",
      "Request failed with status code 422\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"This is the worst service ever.\"}}]}\n",
      "Request failed with status code 422\n",
      "here\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"I'm feeling great today.\"}}]}\n",
      "Request failed with status code 422\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"I am not happy with the results.\"}}]}\n",
      "Request failed with status code 422\n",
      "here\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"The service was acceptable.\"}}]}\n",
      "Request failed with status code 422\n",
      "here\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"Could be better, but I'm satisfied.\"}}]}\n",
      "Request failed with status code 422\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"Not what I expected, quite disappointing.\"}}]}\n",
      "Request failed with status code 422\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"Absolutely fantastic experience!\"}}]}\n",
      "Request failed with status code 422\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"Exceeded all my expectations!\"}}]}\n",
      "Request failed with status code 422\n",
      "{\"detail\":[{\"type\":\"missing\",\"loc\":[\"body\",\"input\"],\"msg\":\"Field required\",\"input\":{\"text\":\"I wouldn't recommend this to anyone.\"}}]}\n",
      "Request failed with status code 422\n",
      "Total time taken: 0.04 seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Define the API endpoint\n",
    "url = 'http://0.0.0.0:8000/infer'\n",
    "\n",
    "# Sample texts for sentiment analysis\n",
    "texts = [\n",
    "    # Add a larger list of texts to better demonstrate concurrency\n",
    "    \"I love this product!\",\n",
    "    \"This is the worst service ever.\",\n",
    "    \"I'm feeling great today.\",\n",
    "    \"I am not happy with the results.\",\n",
    "    \"Could be better, but I'm satisfied.\",\n",
    "    \"Absolutely fantastic experience!\",\n",
    "    \"Not what I expected, quite disappointing.\",\n",
    "    \"The service was acceptable.\",\n",
    "    \"Exceeded all my expectations!\",\n",
    "    \"I wouldn't recommend this to anyone.\",\n",
    "    # Add more texts if desired\n",
    "]\n",
    "\n",
    "def send_request(text):\n",
    "    payload = {'text': text}\n",
    "    try:\n",
    "        print('here')\n",
    "        response = requests.post(url, json=payload)\n",
    "        print(response.text)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"Input Text: {text}\")\n",
    "            print(f\"Predicted Sentiment: {result['sentiment']}\")\n",
    "            print(f\"Confidence Score: {result['confidence']:.4f}\\n\")\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Number of threads to use\n",
    "num_threads = 5\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    futures = [executor.submit(send_request, text) for text in texts]\n",
    "    for future in as_completed(futures):\n",
    "        pass\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n",
      "200 {'prediction': [{'label': 'positive', 'score': 0.9848045110702515}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "url = \"http://localhost:8000/infer\"\n",
    "\n",
    "payload = {\"input\": \"I love this product!\"}\n",
    "\n",
    "# Function to make a POST request\n",
    "def make_request():\n",
    "    response = requests.post(url, json=payload)\n",
    "    print(response.status_code, response.json())\n",
    "\n",
    "# Send 10 parallel requests\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(make_request) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 422\n",
      "Error: 422\n",
      "Error: 422\n",
      "Error: 422\n",
      "Error: 422\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Define the API endpoint and input data\n",
    "url = \"http://0.0.0.0:8000/infer\"\n",
    "texts = [\n",
    "    \"I love this product!\",\n",
    "    \"This is terrible.\",\n",
    "    \"Not sure about this one.\",\n",
    "    \"Could be better.\",\n",
    "    \"Absolutely amazing experience!\"\n",
    "]\n",
    "\n",
    "def send_request(text):\n",
    "    response = requests.post(url, json={\"text\": text})\n",
    "    if response.status_code == 200:\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "# Send requests concurrently\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(send_request, texts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
